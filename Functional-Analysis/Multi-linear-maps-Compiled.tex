\documentclass[../main-manifolds.tex]{subfiles}

\begin{document}
\topheader{Notation}
We will use the following notation to simplify computations with multilinear maps. Let $E$ and $F$ be sets, and $v_1,\ldots, v_k\in E$. $f: E\to F$.
\begin{itemize}
    \item Listing individual elements: $\UL{v}[k]$ means $v_1,\ldots,v_k$ as separate elements. 
    \item Creating a $k$-list: $(\UL{v}[k]) = (v_1,\ldots, v_k)\in \prod E_{j\leq k}$ if $v_i\in E_i$ for $i = \underline{k}$.
    \item Double indices: $(\UL{v}[n_k]) = (v_{n_{\underline{k}}}) = (v_{n_1},\ldots, v_{n_k})$, and
    \[
        (\UL{v}[n_k]) \neq (v_{n_{(1,\ldots,k)}})
    \]
    \item Closest bracket convention:
    \[
        (v_{(n_{\underline{k}})}) = (v_{(n_1, \ldots, n_k)})\qqtext{and}(v_{n_{(\underline{k})})}) = (v_{n_{(1, \ldots, k)}})
    \]
    \item Underlining $0$ means it is iterated $0$ times: 
    \[
        (\UL{v}[0], a,b,c) = (a,b,c)
    \]
    \item Skipping an index: 
    \begin{equation}\label{eq:notation-skipping-index}
        (\UL{v}[i-1],\UL{v}[i+][k-i]) = (v_{1},\ldots, v_{i-1},v_{i+1},\ldots, v_{k})
    \end{equation}
    for $i = \underline{k}$.
    \item Applying $f$ to a particular index: 
    \begin{equation}\label{eq:notation-apply-to-index}
        (\UL{v}[i-1], f(v_{i}), \UL{v}[i+][k-i]) = (v_1,\ldots, v_{i-1}, f(v_i), v_{i+1}, \ldots, v_k)
    \end{equation}
    Of course, if $i=1$, then the above expression reads $(f(v_1), v_2\ldots, v_k)$ by the $\underline{0}$ interpretation.
    \item If $\wedge: E\times E\to F$ is any associative binary operation,
    \[
        \bigowedge(\UL{v}[k]) = v_1\wedge\cdots \wedge v_k
    \]
    \item In any list using this 'underline' notation, we can find the size of a list by summing over all the underlined numbers and the number of terms without an underline. We see \cref{eq:notation-skipping-index}, \cref{eq:notation-apply-to-index} have $k-1$, $k$ terms respectively.
\end{itemize}
\begin{remark}[Preview of exterior calculus]
We can write the cofactor expansion formula of the determinant of a $\real^{k\times k}$ matrix in this notation. Suppose $a_i\in\real$, and $b_i\in\real^{k-1}$ for $i=\underline{k}$.

\[
M = \begin{bmatrix}
    a_1 & \cdots & a_k \\[1ex]
    \vert &  & \vert \\
    b_1 & \cdots & b_k \\
    \vert &  & \vert \\[1ex]
\end{bmatrix}
\]
The determinant of $M$, can then be written as
\[
    \det(M) = \sum_{i=\underline{k}}(-1)^{i-1} a_i\det(\UL{b}[i-1],\UL{b}[i+][k-i])
\]    
\end{remark}

\topheader{$k$-linear maps}
\begin{definition}[$k$-linear maps]\label{def:k-linear-maps}
    Let $\UL{E}[k]$, $F$ be Banach spaces. A map $\varphi: \prod \UL{E}[k]$ is $k$-linear if for every $i=\underline{k}$, $v_i\in E_i$, 
    \[
        \varphi(\UPL{\cdot}[i-1],v_i,\UPL{\cdot}[k-i]):\: \bigoprod (\UL{E}[i-1],\UL{E}[i+][k-i])\to F\quad\text{is }(k-1)\text{-linear}
    \]
\end{definition}
The following theorem should give confidence to the notation we have adopted to use.
\begin{wts}
    Let $\UL{E}[k]$ and $F$ be Banach spaces, a $k$-linear map $\varphi: \prod \UL{E}[k]\to F$ is continuous iff there exists a $C>0$, such that for every $x_i\in E_i$, $i=\underline{k}$
    \[
        \abs{\varphi(\UL{x}[k])} \leq C\prod \abs{\UL{x}[k]}
    \]
\end{wts}
\begin{proof}
    Suppose $\varphi$ is continuous, then it is continuous at the origin. Picking $\varepsilon = 1$ induces a $\delta>0$ such that for $\abs{(\UL{x}[k])}\leq \delta$, $\abs{\varphi(\UL{x}[k])}\leq 1$. The usual trick of normalizing an arbitrary vector $(\UL{x}[k])\in \prod \UL{E}[k]$ does the job:
    \[
        \abs{\varphi(x_k\cdot \abs{\UL{x}[k]}^{-1}\cdot\delta)}\leq 1\implies \abs{\varphi(\UL{x}[k])}\leq \delta^{-k}\prod\abs{\UL{x}[k]}
    \]
    Conversely, fix a sequence (indexed by $n$, in $k$ elements in the product space $\prod\UL{E}[k]$), so
    \begin{equation}\label{eq:k-linear-sequence-def}
        (x_n^{\underline{k}})\to (x^{\underline{k}})\quad \text{as } n\to +\infty
    \end{equation}
    To proceed any further, we need to prove \cref{eq:k-linear-lemma-1} that expresses the difference of two values of $\varphi$ in terms its arguments.
    \begin{equation}\label{eq:k-linear-lemma-1}
        \varphi(\UPL{b}[k]) - \varphi(\UPL{a}[k]) = \sum_{i=\underline{k}}\varphi(\UPL{b}[i-1],\Delta_i, \UPL{a}[i+][k-i])
    \end{equation}
    where $(\UPL{b}[k])$ and $(\UPL{a}[k])$ are elements in $\prod \UL{E}[k]$, and $\Delta_i = b^i - a^i$ for $i = \underline{k}$. The proof is contained in the following note, which is in more detail than usual - to help the reader ease into the new notation.
    \begin{note}
        We proceed by induction, and \cref{eq:k-linear-lemma-1} follows by setting $m=k$ in
        \begin{equation}\label{eq:k-linear-lemma-2}
            \varphi(\UPL{a}[k]) = \varphi(\UPL{b}[m],\UPL{a}[m+][k-m]) - \sum_{i=\underline{m}}\varphi(\UPL{b}[i-1],\Delta_i,\UPL{a}[i+][k-i])
        \end{equation}
        Base case: set $m=1$, by definition of $k$-linearity (\cref{def:k-linear-maps}) of $\varphi$. Since $a^1 = b^1-\Delta_1$, 
        \[
            \varphi(\UPL{a}[k]) = \varphi(b^1-\Delta_1, \UPL{a}[1+][k-1]) = \varphi(b^1, \UPL{a}[1+][k-1]) - \varphi(\Delta_1,\UPL{a}[1+][k-1])
        \]
        Induction hypothesis: suppose \cref{eq:k-linear-lemma-2} holds for a fixed $m$. Since $a^{m+1} = b^{m+1} - \Delta_{m+1}$, 
        \begin{align*}
            \varphi(\UPL{a}[k]) &= \varphi(\UPL{b}[m],\UPL{a}[m+][k-m]) - \sum_{i=\underline{m}}\varphi(\UPL{b}[i-1],\Delta_i,\UPL{a}[i+][k-i])\\
            &= \varphi(\UPL{b}[m],a^{m+1},\UPL{a}[(m+1)+][k-(m+1)]) - \sum_{i=\underline{m}}\varphi(\UPL{b}[i-1],\Delta_i,\UPL{a}[i+][k-i])\\
            &= \varphi(\UPL{b}[m+1],\UPL{a}[(m+1)+][k-(m+1)]) - \varphi(\UPL{b}[m+1],\Delta_{m+1},\UPL{a}[(m+1)+][k-(m+1)]) - \sum_{i=\underline{m}}\varphi(\UPL{b}[i-1],\Delta_i,\UPL{a}[i+][k-i])
        \end{align*}
        and this proves \cref{eq:k-linear-lemma-1}
    \end{note}
    We substitute $a^i = x^i$, and $b^i = x_n^i$ for $i = \underline{k}$, and \cref{eq:k-linear-lemma-1} becomes \cref{klinear-eq}
    \begin{equation}\label{klinear-eq}
        \varphi(x_n^{\underline{k}}) - \varphi(x^{\underline{k}}) = \sum_{i=\underline{k}}\varphi(x_n^{\underline{i-1}}, x_n^i - x^i, x^{i+\underline{k-i}})
    \end{equation}
    Then the triangle inequality reads
    \begin{align*}
        \abs{\varphi(x_n^{\underline{k}}) - \varphi(x^{\underline{k}})} &\leq \sum_{i=\underline{k}} \abs{\varphi(x_n^{\underline{i-1}}, x_n^i - x^i, x^{i+\underline{k-i}})}\\
        &\leq \sum_{i=\underline{k}}\abs{\varphi}\cdot\bigoprod\qty({\UPL{x_n}[i-1],\Delta_i,\UPL{x}[i+][k-i]})\\
        &\leq \sum_{i=\underline{k}}\abs{\varphi}\cdot\abs{x_n^i - x^i}\bigoprod\qty(x_n^{\underline{i-1}}, x^{i+\underline{k-i}})\\
        &\Lsim_n\vert\varphi\vert\sup_{i=\underline{k}}\vert x_n^i - x^i\vert\to 0
    \end{align*}
    where we identify the product $\bigoprod\qty(\UPL{v}[k])$ with the product of their norms $\bigoprod \qty(\abs{\UPL{v}[k]})$. 
\end{proof}
% \begin{remark}
%     The $k$-linear variant of \cref{prop:bilinear-map-isomorphism-currying} holds. We will use but not prove this fact.
% \end{remark}
% \begin{remark}
% We denote the space of $k$-linear maps from $E$ into $F$ by $L(\UL{E}[k]; F) = L(E^k, F) = L^k(E,F)$. \emph{Tensors} on $E$ are $k$-linear maps from the product space of $E$ into $\real$, by replacing $F$ with $\real$.
% \end{remark}
\end{document}